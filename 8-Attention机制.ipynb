{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 - Transformer\n",
    "自[Attention is All You Need](https://arxiv.org/pdf/1706.03762.pdf)的提出已经过去了两年 ... 【而大家发论文的激情愈发澎湃:)学不完了】\n",
    "\n",
    "<img src='images/memes/new_models.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 理论\n",
    "不管怎么说，**`Attention`**是一个非常重要的节点，是对于深度学习模型**结构**的一次革新。\n",
    "\n",
    "在前两节中，我们使用的分类模型就只由一个CNN/RNN模型构成【RNN那一节暂缺】，因为其输出非常简单（标签类）。然而面对稍复杂的问题，如自然语言翻译/生成或问答（**seq2seq**），一次性输出就显得力不从心。\n",
    "\n",
    "在Attention**之前**最常见的结构是`encoder-decoder`模式。\n",
    "\n",
    "<img src='images/encoder_decoder.png'>\n",
    "\n",
    "其中encoder和decoder可以由不同的模型替换，如LSTM、GRU、CNN等。关键在于连接两者的`中间向量`（上图context vector），其作为encoder的输出值，最大程度地提炼输入序列中的信息，然后再作为decoder的输入值，生成新的输出序列。\n",
    "\n",
    "可以看出这是一个单一`线性结构`。中间向量虽然捕捉到了输入序列中每个元素的信息，但实为一锅乱炖。而且随着输出序列变长，其包含的意义也不断消散（参考传声筒游戏）。鉴于seq2seq问题中两个序列的元素经常有一一对应关系，那么是否可以元素间点到点互通，而不要依赖信息的层层传递？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention机制解决的就是这个问题。我们先来看最简单的应用。\n",
    "\n",
    "<img src='images/attention.png'>\n",
    "\n",
    "上图中，encoder的部分（即对输入序列的处理方式）没有变化。但是在decoder中，每个结构单元都有着属于自己的中间向量c，而除了要引入前一个结构单元的输出外，其还要包括encoder中所有单元输出(h)的组合。组合中起决定性因素的就是不同元素所分配到的权值(alpha)。\n",
    "\n",
    "以\"I love you\"到\"我爱你\"为例，理想状态下，对应输出为\"我\"的**结构单元**，其输入中\"I\"所赋予的权值应该最大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "具体的计算可以参考这张图（[出处](https://blog.csdn.net/songbinxu/article/details/80739447)）。权值的计算实际上是考察encoder、decoder中状态量h和c的相似度，对应图中$f_{aat}$函数 + $softmax$函数。\n",
    "\n",
    "<img src='images/attention_machanism.jpeg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总的来说，Attention实际上就是一个权值分配的问题，即:\n",
    "\n",
    "$$c_{我}=\\alpha_{1}*h_{I} + \\alpha_{2}*h_{love} + \\alpha_{3}*h_{you}$$\n",
    "\n",
    "另一个常用的理解思路将其当成**键值查询**，其中$c_{i}$视作query，$h_{i}$为key，对应某个$value_{i}$（可以是其本身），通过$f(c_{i},h_{i})$得到权值$\\alpha_{i}$，再与对应value值相乘，最终求和。写成算式如下：\n",
    "\n",
    "$$Attention(Q,K,V) = softmax(\\frac{QK^T}{\\sqrt{d_{k}}})V$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后再来看一下Google那篇论文中的Transformer模型。我第一眼看都没敢认这是我刚刚学的模型，不过仔细分析，其核心就是`红色方框内的Attention模型`（匹配输入和输出），黄色方框内的是两个`self-Attention`（据说用来提取句子中的长短期依赖，不过我没有深究，直接视作一个预处理步骤），剩下的两个前馈神经网络可以是任意前馈模型，也算是进一步整合数据（修修补补-让结构更好看？）\n",
    "\n",
    "<img src='images/transformer.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 代码\n",
    "\n",
    "至此，理论部分先告一段落。代码相对于原理来说简单得多（因为有现成的模型:D）。\n",
    "\n",
    "此处我们套用[BERT](https://arxiv.org/pdf/1810.04805.pdf) (Bidirectional Encoder Representations from Transformers) \n",
    "\n",
    "注意，如果要用pre-trained model，那就要做全套，包括数据预处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "\n",
    "from torchtext.data import Field, LabelField \n",
    "from torchtext.data import TabularDataset, BucketIterator\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model\n",
    "我们的模型：将原来的embedding层替换为pre-trained BERT模型，其输出作为接下来GRU模型的输入，最后再接一个全连阶层。\n",
    "\n",
    "即：input -> BERT -> GRU -> dropout -> FC -> output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_GRU(nn.Module):\n",
    "    def __init__(self,BERT,config):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bert = BERT\n",
    "        # BERT模型的输出向量大小\n",
    "        embedding_dim = BERT.config.to_dict()['hidden_size']\n",
    "        \n",
    "        # 使用GRU\n",
    "        self.gru = nn.GRU(embedding_dim,\n",
    "                          config.hidden_dim,\n",
    "                          num_layers = config.layers_num,\n",
    "                          bidirectional = config.bidirectional,\n",
    "                          batch_first = True,\n",
    "                          dropout = 0 if config.layers_num < 2 else config.dropout)\n",
    "        \n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.fc = nn.Linear(config.hidden_dim * 2 if config.bidirectional else config.hidden_dim, config.class_num)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x -> (batch_size, seq_length)\n",
    "        # 在BERT模型中的变换不算入反向传播\n",
    "        with torch.no_grad():\n",
    "            embedded = self.bert(x)[0]\n",
    "        # embedded -> (batch_size, seq_length, embed_dim)\n",
    "        \n",
    "        _, hidden = self.gru(embedded)\n",
    "        # hidden -> (layers_num * directions_num, batch_size, hidden_dim)\n",
    "        \n",
    "        # dropout，单双向不同\n",
    "        if self.gru.bidirectional:\n",
    "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        else:\n",
    "            hidden = self.dropout(hidden[-1,:,:])  \n",
    "        # hidden -> (batch_size, hidden_dim)\n",
    "        \n",
    "        output = self.fc(hidden)\n",
    "        # output -> (batch_size, class_num)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train/evaluate/predict/save\n",
    "这一部分仍然是大同小异。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_iterator, test_iterator, config):\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    model.train()\n",
    "\n",
    "    step = 0\n",
    "    best_acc = 0\n",
    "    for epoch in range(1,config.epochs+1):\n",
    "        stop_flag = 0\n",
    "        for batch in train_iter:\n",
    "            step += 1\n",
    "            feature, target = batch.text, batch.label\n",
    "            with torch.no_grad(): # 不计入逆向传播中\n",
    "                target.sub_(1) # target-1，要求从0开始（否则报错）\n",
    "            \n",
    "            # 实际上执行model.forward(feature)操作 -> (batch_size, C)\n",
    "            logit = model(feature) \n",
    "\n",
    "            loss = F.cross_entropy(logit,target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # 生成报告\n",
    "            if step % config.log_interval == 0:\n",
    "                # torch.max(logit,1)[1]取logit第二维中的最大值，即概率最高的类别\n",
    "                # view相当于reshape\n",
    "                corrects = (torch.max(logit,1)[1].view(target.size()).data == target.data).sum()\n",
    "                accuracy = 100.0 * corrects/batch.batch_size\n",
    "                # '\\r'实现覆盖输出\n",
    "                sys.stdout.write(f\"\\rStep[{step}] - loss: {loss.item():.6f} \\\n",
    "                    acc: {accuracy:.4f}%({corrects.item()}/{batch.batch_size})\")\n",
    "            \n",
    "            # 阶段测试、模型保存，并判断是否提前结束训练\n",
    "            if step % config.test_interval == 0:\n",
    "                test_acc = evaluate(model,test_iter)\n",
    "                if test_acc > best_acc:\n",
    "                    best_acc = test_acc\n",
    "                    last_step = step\n",
    "                    save(model, config.save_dir, 'best', step)\n",
    "                else:\n",
    "                    if step - last_step >= config.early_stop:\n",
    "                        print('early stop by {} steps.'.format(config.early_stop))\n",
    "                        stop_flag = 1\n",
    "                        break\n",
    "        if stop_flag: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,data_iter):\n",
    "    # 将self.training设置为False\n",
    "    model.eval() \n",
    "    \n",
    "    corrects, avg_loss = 0,0\n",
    "    for batch in data_iter: #注意这里的batch表示多组evaluation，最后取平均即可\n",
    "        feature, target = batch.text, batch.label\n",
    "        with autograd.no_grad():\n",
    "            target.data.sub_(1)\n",
    "\n",
    "        logit = model(feature)\n",
    "        # reduction='sum'表示每个batch内部不取平均\n",
    "        loss = F.cross_entropy(logit,target,reduction='sum') \n",
    "\n",
    "        avg_loss += loss.item()\n",
    "        corrects += (torch.max(logit,1)[1].view(target.size()).data \n",
    "                    == target.data).sum()\n",
    "\n",
    "    size = len(data_iter.dataset)\n",
    "    avg_loss /= size \n",
    "    accuracy = 100.0 * corrects/size \n",
    "    print(f\"\\nEvaluation - loss: {avg_loss:.6f} acc: {accuracy:.4f}%({corrects}/{size})\\n\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text,model,text_field,label_field):\n",
    "    assert isinstance(text,str), \"plz use str object as input.\"\n",
    "    # 将self.training设置为False\n",
    "    model.eval()\n",
    "    \n",
    "    # 相当于生成一个example\n",
    "    text = text_field.preprocess(text)\n",
    "    x = torch.tensor(text) # -> (batch_size,seq_length), batch_size=1\n",
    "    x = autograd.Variable(x)\n",
    "    \n",
    "    output = model(x)\n",
    "    _, pred = torch.max(output,1)\n",
    "    # pred.item()等价于pred.data[0]\n",
    "    print(label_field.vocab.itos[pred.item()+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(model,save_dir,save_prefix,steps):\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    save_path = f\"{save_dir}/{save_prefix}_steps_{steps}.pt\"\n",
    "    torch.save(model.state_dict(),save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    bidirectional = True # de:True\n",
    "    layers_num = 2 # de:2\n",
    "    class_num = 2 # de:2\n",
    "    hidden_dim = 128 # de:128\n",
    "    dropout = 0.5 #de:0.5\n",
    "    \n",
    "    # training\n",
    "    lr = 0.001 # de:0.001\n",
    "    epochs = 5 # de:5\n",
    "    batch_size = 96 # de:64\n",
    "    log_interval = 1 # de:1\n",
    "    test_interval = 100 # de:100\n",
    "    early_stop = 1000 # de:1000\n",
    "    save_dir = 'model/BERT_GRU'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main\n",
    "注意此处的数据预处理要与pre-trained模型的一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 102 0 100\n",
      "512\n",
      "Number of training examples: 8796\n",
      "Number of validation examples: 3769\n",
      "Number of testing examples: 5386\n",
      "defaultdict(None, {'KIRK': 0, 'SPOCK': 1, 'MCCOY': 2})\n"
     ]
    }
   ],
   "source": [
    "### 数据 ###\n",
    "config = Config()\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# 需要特别关照这几个特殊符号 -> [CLS],[SEP],[PAD],[UNK]\n",
    "init_token_idx = tokenizer.cls_token_id\n",
    "eos_token_idx = tokenizer.sep_token_id\n",
    "pad_token_idx = tokenizer.pad_token_id\n",
    "unk_token_idx = tokenizer.unk_token_id\n",
    "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)\n",
    "\n",
    "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
    "print(max_input_length)\n",
    "\n",
    "def my_tokenize(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence) \n",
    "    tokens = tokens[:max_input_length-2]\n",
    "    return tokens\n",
    "\n",
    "text_field = Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = my_tokenize,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids, #此处替代了text_field.build_vocab\n",
    "                  init_token = init_token_idx,\n",
    "                  eos_token = eos_token_idx,\n",
    "                  pad_token = pad_token_idx,\n",
    "                  unk_token = unk_token_idx)\n",
    "\n",
    "label_field = LabelField(dtype = torch.float)\n",
    "\n",
    "data_path = 'processed_data'\n",
    "train_dataset, test_dataset = TabularDataset.splits(\n",
    "        path=data_path, format='csv', skip_header=True,\n",
    "        train='best3_train.csv', test='best3_test.csv',\n",
    "        fields=[('text',text_field),('label',label_field)]) # 按顺序来的\n",
    "\n",
    "train_dataset, valid_dataset = train_dataset.split(random_state = random.seed(888))\n",
    "print(f\"Number of training examples: {len(train_dataset)}\")\n",
    "print(f\"Number of validation examples: {len(valid_dataset)}\")\n",
    "print(f\"Number of testing examples: {len(test_dataset)}\")\n",
    "\n",
    "label_field.build_vocab(train_dataset)\n",
    "with open('model/label_field.txt','wb') as f:\n",
    "    pickle.dump(label_field, f)\n",
    "print(label_field.vocab.stoi)\n",
    "\n",
    "train_iter, valid_iter, test_iter = BucketIterator.splits(\n",
    "                            (train_dataset, valid_dataset, test_dataset), batch_size = config.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我，再一次，卡死，在了，下载，上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/transformers/modeling_utils.py\", line 415, in from_pretrained\n",
      "    state_dict = torch.load(resolved_archive_file, map_location='cpu')\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/torch/serialization.py\", line 426, in load\n",
      "    return _load(f, map_location, pickle_module, **pickle_load_args)\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/torch/serialization.py\", line 620, in _load\n",
      "    deserialized_objects[key]._set_from_file(f, offset, f_should_read_directly)\n",
      "RuntimeError: unexpected EOF, expected 9352645 more bytes. The file might be corrupted.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3325, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-13-c121670163ba>\", line 4, in <module>\n",
      "    BERT = BertModel.from_pretrained('bert-base-uncased')\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/transformers/modeling_utils.py\", line 417, in from_pretrained\n",
      "    raise OSError(\"Unable to load weights from pytorch checkpoint file. \"\n",
      "OSError: Unable to load weights from pytorch checkpoint file. If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True. \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2039, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'OSError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\n",
      "    fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(__file__)])\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/imp.py\", line 296, in find_module\n",
      "    raise ImportError(_ERR_MSG.format(name), name=name)\n",
      "ImportError: No module named '_pywrap_tensorflow_internal'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\n",
      "    import _pywrap_tensorflow_internal\n",
      "ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow_core/__init__.py\", line 42, in <module>\n",
      "    from . _api.v2 import audio\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow_core/_api/v2/audio/__init__.py\", line 10, in <module>\n",
      "    from tensorflow.python.ops.gen_audio_ops import decode_wav\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_audio_ops.py\", line 10, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/__init__.py\", line 49, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow.py\", line 74, in <module>\n",
      "    raise ImportError(msg)\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/transformers/modeling_utils.py\", line 415, in from_pretrained\n",
      "    state_dict = torch.load(resolved_archive_file, map_location='cpu')\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/torch/serialization.py\", line 426, in load\n",
      "    return _load(f, map_location, pickle_module, **pickle_load_args)\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/torch/serialization.py\", line 620, in _load\n",
      "    deserialized_objects[key]._set_from_file(f, offset, f_should_read_directly)\n",
      "RuntimeError: unexpected EOF, expected 9352645 more bytes. The file might be corrupted.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3325, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-13-c121670163ba>\", line 4, in <module>\n",
      "    BERT = BertModel.from_pretrained('bert-base-uncased')\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/transformers/modeling_utils.py\", line 417, in from_pretrained\n",
      "    raise OSError(\"Unable to load weights from pytorch checkpoint file. \"\n",
      "OSError: Unable to load weights from pytorch checkpoint file. If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True. \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2039, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'OSError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\n",
      "    fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(__file__)])\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/imp.py\", line 296, in find_module\n",
      "    raise ImportError(_ERR_MSG.format(name), name=name)\n",
      "ImportError: No module named '_pywrap_tensorflow_internal'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\n",
      "    import _pywrap_tensorflow_internal\n",
      "ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "\n",
      "See https://www.tensorflow.org/install/errors\n",
      "\n",
      "for some common reasons and solutions.  Include the entire stack trace\n",
      "above this error message when asking for help.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/transformers/modeling_utils.py\", line 415, in from_pretrained\n",
      "    state_dict = torch.load(resolved_archive_file, map_location='cpu')\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/torch/serialization.py\", line 426, in load\n",
      "    return _load(f, map_location, pickle_module, **pickle_load_args)\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/torch/serialization.py\", line 620, in _load\n",
      "    deserialized_objects[key]._set_from_file(f, offset, f_should_read_directly)\n",
      "RuntimeError: unexpected EOF, expected 9352645 more bytes. The file might be corrupted.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3325, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-13-c121670163ba>\", line 4, in <module>\n",
      "    BERT = BertModel.from_pretrained('bert-base-uncased')\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/transformers/modeling_utils.py\", line 417, in from_pretrained\n",
      "    raise OSError(\"Unable to load weights from pytorch checkpoint file. \"\n",
      "OSError: Unable to load weights from pytorch checkpoint file. If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True. \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2039, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'OSError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3248, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3342, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2042, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1385, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1288, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1150, in structured_traceback\n",
      "    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\n",
      "TypeError: can only concatenate str (not \"list\") to str\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2039, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\n",
      "    fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(__file__)])\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/imp.py\", line 296, in find_module\n",
      "    raise ImportError(_ERR_MSG.format(name), name=name)\n",
      "ImportError: No module named '_pywrap_tensorflow_internal'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\n",
      "    import _pywrap_tensorflow_internal\n",
      "ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow_core/__init__.py\", line 42, in <module>\n",
      "    from . _api.v2 import audio\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow_core/_api/v2/audio/__init__.py\", line 10, in <module>\n",
      "    from tensorflow.python.ops.gen_audio_ops import decode_wav\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_audio_ops.py\", line 10, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/__init__.py\", line 49, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow.py\", line 74, in <module>\n",
      "    raise ImportError(msg)\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/transformers/modeling_utils.py\", line 415, in from_pretrained\n",
      "    state_dict = torch.load(resolved_archive_file, map_location='cpu')\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/torch/serialization.py\", line 426, in load\n",
      "    return _load(f, map_location, pickle_module, **pickle_load_args)\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/torch/serialization.py\", line 620, in _load\n",
      "    deserialized_objects[key]._set_from_file(f, offset, f_should_read_directly)\n",
      "RuntimeError: unexpected EOF, expected 9352645 more bytes. The file might be corrupted.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3325, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-13-c121670163ba>\", line 4, in <module>\n",
      "    BERT = BertModel.from_pretrained('bert-base-uncased')\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/transformers/modeling_utils.py\", line 417, in from_pretrained\n",
      "    raise OSError(\"Unable to load weights from pytorch checkpoint file. \"\n",
      "OSError: Unable to load weights from pytorch checkpoint file. If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True. \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2039, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'OSError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3248, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3342, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2042, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1385, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1288, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1150, in structured_traceback\n",
      "    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\n",
      "TypeError: can only concatenate str (not \"list\") to str\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2039, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\n",
      "    fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(__file__)])\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/imp.py\", line 296, in find_module\n",
      "    raise ImportError(_ERR_MSG.format(name), name=name)\n",
      "ImportError: No module named '_pywrap_tensorflow_internal'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"/Users/inkding/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\n",
      "    import _pywrap_tensorflow_internal\n",
      "ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "\n",
      "See https://www.tensorflow.org/install/errors\n",
      "\n",
      "for some common reasons and solutions.  Include the entire stack trace\n",
      "above this error message when asking for help.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"list\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m                 \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_archive_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m         \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_should_read_directly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: unexpected EOF, expected 9352645 more bytes. The file might be corrupted.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2038\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2039\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2040\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'OSError' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result, async_)\u001b[0m\n\u001b[1;32m   3340\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3341\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3342\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_compiled_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3343\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3344\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2040\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2041\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2042\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1383\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1385\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1286\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1288\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m             )\n\u001b[1;32m   1290\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parts_of_chained_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m             \u001b[0mformatted_exceptions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_chained_exception_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cause__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m             \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"list\") to str"
     ]
    }
   ],
   "source": [
    "### 模型 ###\n",
    "# 生成模型\n",
    "config.class_num = len(label_field.vocab) - 1\n",
    "BERT = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_gru = BERT_GRU(BERT,config)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "def freeze_bert_params(model):\n",
    "    for name, param in model.named_parameters():                \n",
    "        if name.startswith('bert'):\n",
    "            param.requires_grad = False\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} parameters all together.')\n",
    "freeze__bert_params(model)\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "# 删除之前训练的模型\n",
    "for file in os.listdir(config.save_dir):\n",
    "    if file.find('.pt')>=0:\n",
    "        os.remove(os.path.join(config.save_dir,file))\n",
    "    \n",
    "try:\n",
    "    train(bert_gru,train_iter,valid_iter,config)\n",
    "except KeyboardInterrupt:\n",
    "    print('\\n'+'-'*88)\n",
    "    print(\"interrupted by keyboard, stop training...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择最优模型\n",
    "models_path = list(filter(lambda x:x.find('.pt')>0, os.listdir('model')))\n",
    "models_path = list(map(lambda x:os.path.join('model',x), models_path))\n",
    "models_path = list(sorted(models_path, key=lambda x:os.path.getmtime(x)))\n",
    "best_model_path = models_path[-1]\n",
    "# 注意重载时的模型类要和之前的一样\n",
    "bert_gru = BERT_GRU(bert,config)\n",
    "state_dict = torch.load(best_model_path)\n",
    "bert_gru.load_state_dict(state_dict)\n",
    "\n",
    "# 模型评价\n",
    "try:\n",
    "    evaluate(bert_gru,test_iter)\n",
    "except:\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测->交互式\n",
    "with open('model/label_field.txt','rb') as f:\n",
    "    label_field = pickle.load(f)\n",
    "while True:\n",
    "    try:\n",
    "        text = input(\"Plz enter a sentence for prediction:\\n\")\n",
    "        predict(text,bert_gru,text_field,label_field)\n",
    "        print()\n",
    "    except KeyboardInterrupt:\n",
    "        print('Exiting...')\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
